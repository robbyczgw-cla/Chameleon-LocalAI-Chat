# Memory System - Complete Guide

Your chat application has **TWO separate memory systems** that work together to create a persistent, context-aware AI experience. Here's everything you need to know:

---

## üß† System 1: AI Long-Term Memory (User Memory)

**Location**: Settings ‚Üí AI Memory tab
**Storage**: `localStorage` key: `chat_memories`
**Service**: `lib/memory-service.ts`

### What It Does
Stores **facts about YOU** that persist across all chats and personas. Think of it as the AI's notebook about you.

### Memory Types

1. **Preferences** - Your likes, dislikes, habits
   - Example: "Prefers dark mode themes", "Likes concise responses", "Works in software development"

2. **Facts** - Objective information about you
   - Example: "Lives in Berlin", "Speaks English and German", "Uses React and TypeScript"

3. **Context** - Background information
   - Example: "Currently working on an e-commerce project", "Learning about AI systems"

4. **Skills** - Your abilities and expertise
   - Example: "Expert in frontend development", "Familiar with Python", "Learning machine learning"

5. **Goals** - Your objectives and aspirations
   - Example: "Building a SaaS product", "Learning system design", "Improving TypeScript skills"

### How It Works

#### Storage & Retrieval
```typescript
// Memory Structure
{
  id: "uuid",
  type: "preference" | "fact" | "context" | "skill" | "goal",
  content: "Prefers functional programming",
  importance: 1 | 2 | 3,  // 1=low, 2=medium, 3=high
  category: "coding-style",  // Optional grouping
  createdAt: 1234567890,
  lastAccessedAt: 1234567890,
  accessCount: 5
}
```

#### Intelligent Retrieval (Token-Efficient)
When you send a message, the system scores each memory based on:

1. **Importance Weight** (0-30 points)
   - High importance (3): 30 points
   - Medium importance (2): 20 points
   - Low importance (1): 10 points

2. **Keyword Matching** (0-50 points)
   - Each matching word in content: +10 points
   - Each matching word in category: +5 points

3. **Recency Bonus** (0-20 points)
   - Created within 7 days: +20 points
   - Created within 30 days: +10 points
   - Created within 90 days: +5 points

Only the top-ranked memories (default: 5) are included in the AI's context.

#### Context Injection
Memories are formatted and injected into every AI message like this:

```xml
<user_memory>
Preferences: Prefers dark themes; Likes concise responses; Works late at night
Facts: Lives in Berlin; Speaks English and German; Uses TypeScript
Context: Building an e-commerce SaaS; Using Next.js 16 and Tailwind
Skills: Expert in React; Familiar with Node.js; Learning system design
Goals: Launch product in 3 months; Improve backend skills
</user_memory>
```

This uses **minimal tokens** while providing maximum context.

### Settings
- **enabled**: Turn the entire system on/off
- **autoExtract**: Automatically extract memories from conversations (future feature)
- **maxMemoriesInContext**: How many memories to include (default: 5)
- **importanceThreshold**: Minimum importance to include (default: 2)

### Use Cases
‚úÖ **Great for:**
- Remembering your coding preferences
- Recalling your project context
- Understanding your skill level
- Personalizing responses to your needs

‚ùå **Not for:**
- Temporary conversation context (use chat history for that)
- Persona-specific interactions (use Persona Memory for that)

---

## üé≠ System 2: Persona Memory (Conversation History)

**Location**: Per-persona basis
**Storage**: `localStorage` key: `persona-memories`
**Service**: `lib/persona-memory-service.ts`

### What It Does
Each persona (Coder, Writer, Cogito, etc.) **remembers past conversations** with you specifically.

### How It Works

#### Storage Structure
```typescript
{
  "coder": [  // Persona ID
    {
      id: "conv-1234567890",
      personaId: "coder",
      timestamp: 1234567890,
      summary: "Discussed React hooks optimization",
      topics: ["React", "performance", "useMemo", "useCallback"],
      userMessages: ["How do I optimize...", "What about useCallback?"],
      assistantMessages: ["You can use useMemo...", "useCallback is for..."]
    }
  ],
  "writer": [...],
  "cogito": [...]
}
```

#### Context Building
When you chat with a persona, it retrieves:
- Up to 10 most recent conversations (configurable)
- Truncates to 2000 characters max to avoid token bloat
- Formats as narrative context:

```
I remember we previously discussed:
- React hooks optimization (focusing on performance and memoization)
- Async state management patterns
```

#### Automatic Summarization
After each conversation, the persona can save:
- **Summary**: Brief description of what was discussed
- **Topics**: Key subjects covered
- **Sample messages**: Representative exchanges for context

### Settings
- **maxConversations**: Number of past chats to remember (default: 10)
- **maxContextLength**: Character limit for injected context (default: 2000)

### Use Cases
‚úÖ **Great for:**
- Continuing projects with a specific persona
- Maintaining conversation threads across sessions
- Building rapport with a particular AI personality
- Avoiding repetition when working on long-term tasks

‚ùå **Not for:**
- Storing universal facts about you (use Long-Term Memory)
- Sharing context across different personas

---

## üîÑ How The Two Systems Work Together

### Example Scenario

You're working with the **Coder** persona on a React project:

1. **Long-Term Memory** knows:
   - "Prefers TypeScript over JavaScript"
   - "Works with Next.js 16"
   - "Likes functional programming"

2. **Persona Memory (Coder)** knows:
   - Previous conversation: "Built custom React hooks for auth"
   - Topics discussed: ["authentication", "JWT", "refresh tokens"]

3. **Combined Context** sent to AI:
```xml
<user_memory>
Preferences: Prefers TypeScript; Likes functional programming
Context: Working with Next.js 16
Skills: Expert in React
</user_memory>

I remember we previously discussed:
- Building custom React hooks for authentication
- JWT token management and refresh strategies
```

This gives the AI **both** universal knowledge about you **and** specific conversation history.

---

## üõ†Ô∏è Managing Your Memories

### AI Long-Term Memory (Settings ‚Üí AI Memory)

**Adding Memories:**
1. Click "+ Add Memory"
2. Select type (Preference, Fact, Context, Skill, Goal)
3. Write content (be specific!)
4. Set importance (1-3)
5. Add category (optional)

**Best Practices:**
- ‚úÖ Write specific, actionable memories
  - Good: "Prefers functional components over class components in React"
  - Bad: "Likes React"

- ‚úÖ Use importance wisely
  - High (3): Critical information that should always be included
  - Medium (2): Relevant but not essential
  - Low (1): Nice-to-have context

- ‚úÖ Categorize for better organization
  - Examples: "coding-style", "project-context", "learning-goals"

- ‚úÖ Keep it current
  - Delete outdated memories
  - Update changed preferences

**Viewing Statistics:**
- Total memories by type
- Most accessed memories
- Recent activity

### Persona Memory

**Automatic**: Personas automatically save conversations
**Manual Control**: Coming soon - ability to edit/delete specific conversation memories

---

## üéØ When To Use Which System

| Situation | Use This Memory System |
|-----------|------------------------|
| General facts about you | Long-Term Memory |
| Coding preferences that apply everywhere | Long-Term Memory |
| Current project context | Long-Term Memory (Context type) |
| Continuing a specific discussion with Coder | Persona Memory (automatic) |
| Teaching Cogito about your philosophy | Persona Memory (automatic) |
| Working on a story with Writer | Persona Memory (automatic) |
| Skills you want every persona to know | Long-Term Memory |

---

## üìä Technical Details

### Token Efficiency

**Without Memory:**
- User has to repeat context every conversation
- Wastes 50-200 tokens per message explaining preferences
- No continuity between sessions

**With Memory:**
- One-time memory injection: ~50-100 tokens
- Reused across all messages in chat
- 80% reduction in repeated information

### Performance

**Long-Term Memory:**
- Keyword-based scoring: O(n*m) where n=memories, m=query tokens
- Typical lookup: <5ms for 100 memories
- Storage: ~1KB per 10 memories

**Persona Memory:**
- Simple timestamp-based retrieval: O(n log n)
- Typical lookup: <1ms
- Storage: ~500 bytes per conversation

### Privacy & Data

**All memories stored locally:**
- Saved in browser localStorage
- Never sent to external servers
- Persists across sessions
- Cleared when you clear browser data

**Syncing (if enabled):**
- Can sync to Supabase for cross-device access
- End-to-end encrypted (coming soon)

---

## üêõ Troubleshooting

### "Memory toggle doesn't stay enabled after reload"
**Fixed!** This was a bug where the local component state wasn't syncing with saved settings. Now resolved.

### "AI doesn't seem to use my memories"
**Check:**
1. Is Long-Term Memory enabled? (Settings ‚Üí AI Memory ‚Üí Toggle)
2. Are your memories important enough? (Set importance to 2 or 3)
3. Are you using relevant keywords in your messages?
4. Check browser console for "[Memory]" logs

### "Too many memories in context, responses feel bloated"
**Solution:**
- Reduce `maxMemoriesInContext` to 3
- Increase `importanceThreshold` to 3 (only high-importance)
- Delete low-value memories

### "Persona doesn't remember previous conversation"
**Check:**
1. Are you using the same persona?
2. Clear cache and reload
3. Check browser console for "[PersonaMemory]" logs

---

## üöÄ Advanced Usage

### Power User Tips

1. **Strategic Memory Management**
   - Create category-based memory groups
   - Use importance to prioritize what matters
   - Regularly prune outdated memories

2. **Context Optimization**
   - Keep memories concise (under 100 characters)
   - Use semicolons to separate multiple facts in one memory
   - Group related preferences together

3. **Persona Specialization**
   - Let Coder remember all technical discussions
   - Let Writer remember creative projects
   - Let Cogito build philosophical context over time

4. **Multi-Project Workflow**
   - Use categories to separate project contexts
   - Temporarily disable non-relevant memories
   - Create project-specific memory sets

### Developer Notes

**Extending the system:**
```typescript
// Add custom memory type
export interface Memory {
  type: "preference" | "fact" | "context" | "skill" | "goal" | "custom"
  // ... rest of interface
}

// Custom scoring algorithm
memoryService.getRelevantMemories = (query, customScorer) => {
  // Your logic here
}
```

---

## üìù Summary

Your chat app has TWO memory systems:

1. **Long-Term Memory** (AI Memory)
   - Universal facts about YOU
   - Shared across all personas
   - Keyword-based retrieval
   - Manages: preferences, facts, context, skills, goals

2. **Persona Memory**
   - Persona-specific conversation history
   - Remembers past discussions
   - Chronological retrieval
   - Auto-summarizes conversations

Together, they create a **truly personalized AI** that:
- ‚úÖ Remembers who you are
- ‚úÖ Understands your preferences
- ‚úÖ Maintains conversation continuity
- ‚úÖ Learns from past interactions
- ‚úÖ Adapts to your needs

All while staying **token-efficient** and **privacy-focused**.

---

**Need help?** Check the AI Memory Hub in Settings for live statistics and management tools.

Last updated: 2025-11-17
